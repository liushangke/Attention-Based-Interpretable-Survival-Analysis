{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install openslide, histomics_stream, pandas\n",
    "!apt-get update\n",
    "!apt-get install -y openslide-tools\n",
    "!pip install openslide-python\n",
    "!pip install histomics_stream 'large_image[openslide]' scikit_image --find-links https://girder.github.io/large_image_wheels\n",
    "!pip install pandas\n",
    "\n",
    "# install mil\n",
    "user = '########' #git username\n",
    "token = '################################' #personal access token - see https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token\n",
    "!git clone https://{user}:{token}@github.com/PathologyDataScience/mil.git\n",
    "!pip install -e mil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mil.io.reader import read_record\n",
    "from mil.io.writer import split_inference, write_record\n",
    "from mil.io.utils import inference, study\n",
    "from mil.models import convolutional_model\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#parameters\n",
    "t=224\n",
    "overlap=0\n",
    "chunk=1792\n",
    "magnification=20\n",
    "tol=0.02\n",
    "tile_batch=128\n",
    "tile_prefetch=2\n",
    "labels = ['i', 't']\n",
    "model_name='EfficientNetB3'\n",
    "svspath = '/data/transplant/nwu/wsi/'\n",
    "csvfile = '/data/transplant/nwu/CTOT08_clinical_BiopsyImageKeys.csv'\n",
    "output = '/tf/notebooks/transplant/3d/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a wrapped model that consumes tiles and tile metadata.\n",
    "# tf.keras.Model.predict takes a single input, and so we combine \n",
    "# (tiles, tile_metadata) for passing to the wrapped model. Inside\n",
    "# the wrapper these are separated and inference is done on the tiles.\n",
    "# To avoid predict discarding the tile_metadata, we add a dummy 'y' \n",
    "# variable 0. to be discarded by predict.\n",
    "\n",
    "# define the wrapped model class\n",
    "class WrappedModel(tf.keras.Model):\n",
    "    def __init__(self, extractor, *args, **kwargs):\n",
    "        super(WrappedModel, self).__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "        \n",
    "    def call(self, inputs, *args, **kwargs):\n",
    "        return self.model(inputs[0]), inputs[1]\n",
    "    \n",
    "\n",
    "# create the feature extractor model to be wrapped\n",
    "model = tf.keras.applications.efficientnet.EfficientNetB3(\n",
    "        include_top=False, weights='imagenet', input_shape=(t, t, 3),\n",
    "        pooling='avg')\n",
    "\n",
    "# create a distributed wrapped model\n",
    "with tf.distribute.MirroredStrategy().scope():\n",
    "    \n",
    "    # wrap the model\n",
    "    wrapped_model = WrappedModel(model, name='wrapped_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate .tfr test data\n",
    "\n",
    "# extract labels from csv\n",
    "table = pd.read_csv(csvfile)\n",
    "table = table[['SVS_FileName', 'I', 'T']]\n",
    "table = table.dropna()\n",
    "table = table.rename(columns={'SVS_FileName': \"name\", \"I\": \"i_score\", \"T\": \"t_score\"})\n",
    "table = table.rename(columns={c:c.split('_')[0] for c in table.columns if '_score' in c})\n",
    "\n",
    "# match table entries to existing files\n",
    "files = [slide for slide in os.listdir(svspath) if os.path.splitext(slide)[1] == '.svs']\n",
    "table = table[table.name.isin(files)].reset_index()\n",
    "\n",
    "# select two slides\n",
    "slide_1 = table.loc[0]['name']\n",
    "slide_2 = table.loc[1]['name']\n",
    "\n",
    "# extract labels for these slides\n",
    "labels_1 = {l:float(table.loc[0][l]) for l in table.loc[0].keys() if l != 'name'}\n",
    "\n",
    "# create studies for two slides\n",
    "study_1 = study([svspath+slide_1], (t, t), (overlap, overlap), (chunk, chunk), magnification)\n",
    "\n",
    "# do inference for two slides\n",
    "features_1, tile_info_1 = inference(wrapped_model, study_1, batch=tile_batch, prefetch=tile_prefetch)\n",
    "\n",
    "# write one slide as both 2d, 3d in separate files\n",
    "write_record(output + '2d.tfr', features_1, tile_info_1, labels_1, structured=False)\n",
    "write_record(output + '3d.tfr', features_1, tile_info_1, labels_1, structured=True)\n",
    "\n",
    "# write a single record containing two slides\n",
    "study_c = study([svspath+slide_1, svspath+slide_2], \n",
    "                       (t, t), (overlap, overlap), (chunk, chunk), magnification)\n",
    "features_c, tile_info_c = inference(wrapped_model, study_c, batch=tile_batch, prefetch=tile_prefetch)\n",
    "write_record(output + 'combined_2d.tfr', features_c, tile_info_c, labels_1, structured=False)\n",
    "\n",
    "# write a record for each slide independently\n",
    "features_c, tile_info_c = split_inference(features_c, tile_info_c)\n",
    "for i, (features, tile_info) in enumerate(zip(features_c, tile_info_c)):\n",
    "    write_record(output + 'combined_' + str(i) + '_2d.tfr',\n",
    "                 features, tile_info, labels_1, structured=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "# function for comparing tile info\n",
    "def compare_tile_info(t1, t2):\n",
    "    [tf.debugging.assert_equal(t1[k], t2[k]) for k in t1.keys()]\n",
    "    \n",
    "    \n",
    "# function for comparing 2D arrays that are not aligned\n",
    "def compare_unaligned_2d(f1, f2, t1, t2):\n",
    "    matches = []\n",
    "    for x,y in zip(t1['tile_left'], t1['tile_top']):\n",
    "        matches.append(\n",
    "            tf.where(\n",
    "                tf.logical_and(\n",
    "                    x == t2['tile_left'],\n",
    "                    y == t2['tile_top'])\n",
    "            ).numpy()[0][0]\n",
    "        )\n",
    "    matches = tf.constant(matches)\n",
    "    tf.debugging.assert_equal(f1, tf.gather(f2, matches, axis=0))\n",
    "    \n",
    "\n",
    "# read in files used for comparisons\n",
    "def read(path, label, structured):\n",
    "    ds = tf.data.TFRecordDataset(path)\n",
    "    serialized = list(ds.take(1))[0]\n",
    "    f, l, s, t = read_record(serialized, label, False)\n",
    "    return f, l, s, t\n",
    "f_2, l_2, s_2, t_2 = read(output + '2d.tfr', labels, False)\n",
    "f_3, l_3, s_3, t_3 = read(output + '3d.tfr', labels, True)\n",
    "f_c, l_c, s_c, t_c = read(output + 'combined_2d.tfr', labels, False)\n",
    "\n",
    "# compare file stored/read as 2D, file stored as 3D read as 2D\n",
    "f, l, s, ti = read(output + '3d.tfr', labels, False)\n",
    "tf.debugging.assert_near(f_2, f)\n",
    "assert l_2 == l\n",
    "assert s_2 == s\n",
    "compare_tile_info(t_2, ti)\n",
    "\n",
    "# compare file stored/read as 3D, file stored as 2D read as 3D\n",
    "f, l, s, ti = read(output + '2d.tfr', labels, True)\n",
    "tf.debugging.assert_near(f_3, f)\n",
    "assert l_3 == l\n",
    "assert s_3 == s\n",
    "compare_tile_info(t_3, ti)\n",
    "\n",
    "# compare contents of jointly stored slides and independently stored slides\n",
    "f, l, s, ti = read(output + 'combined_0_2d.tfr', labels, False)\n",
    "f0 = f_c[t_c['slide_index'] == 0]\n",
    "t0 = {k: t_c[k][t_c['slide_index'] == 0] for k in t_c.keys()}\n",
    "compare_unaligned_2d(f, f0, ti, t0)\n",
    "\n",
    "f, l, s, ti = read(output + 'combined_1_2d.tfr', labels, False)\n",
    "f1 = f_c[t_c['slide_index'] == 1]\n",
    "t1 = {k: t_c[k][t_c['slide_index'] == 1] for k in t_c.keys()}\n",
    "compare_unaligned_2d(f, f1, ti, t1)\n",
    "\n",
    "# try writing output as structured from multiple files (should error)\n",
    "#write_record(output + 'combined_3d.tfr', features_c, tile_info_c, labels_1, structured=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
