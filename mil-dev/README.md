# mil
Models and utilities for multiple instance and weakly-supervised learning (MIL/WS).

## Overview

This library contains data generation and model building tools creating MIL/WS models from whole-slide imaging datasets. It works with _HistomicsStream_ to make feature extraction easy, and provides convenient TFRecord-based storage formats to support a variety of MIL/WS modeling paradigms.

## Installation

mil depends on HistomicsStream which can be installed easily using Python wheels

```
sudo apt update
sudo apt install -y python3-openslide openslide-tools
pip install histomics_stream 'large_image[openslide]' \
  scikit_image --find-links https://girder.github.io/large_image_wheels
```

Large Image requires a tile source such as OpenSlide to be installed, and can support a number of tile sources including `large_image[openslide,ometiff,openjpeg,bioformats]`.

## Contents

- [Feature extraction](#feature-extraction)
- [Models](#models)
- [Data format](#data-format)
- [Contributing](#contributing)
- [Future work](#future-work)


## Feature extraction

The first step in model building is to extract features from your whole-slide images (WSIs). To do this we use HistomicsStream to create a tile-stream that efficiently reads pixels directly from the WSI files and into a feature-extraction network that transforms these tiles into feature vectors. Tools are provided to write these feature vectors and slide and tile metadata into a TFRecord file (.tfr) to be used for training and validating MIL/WS models. Features can be writte in in either a flattened (2D) format or a structured (3D) format that preserves the spatial relationship between tiles (see Modeling below).

Steps for dataset generation (see mil_example.ipynb):
1. Select a magnification, tile size, and tile overlap and create a HistomicsStream study for each slide using `mil.utils.study`.
2. Load a feature extraction model like a pre-trained network from `tf.keras.applications`.
3. Use `mil.utils.inference` to extract features and `mil.io.write_record` to write them out to .tfr 

Highlights:
- `mil.io.read_record` load data in flattened or structure format, regardless of how it was stored.
- HistomicsStream can accept a tissue mask for each WSI to accelereate feature extraction and to reduce file sizes for flattened tensors.
- Multiple slides / case are supported for flattened tensor storage.

### Wrapping models for feature extraction

When extracting features, the inference of feature vectors may happen in a different order than is described in the HistomicsStream study. For this reason, we capture the tile metadata generated by HistomicsStream during inference, so that we can link each feature vector to a specific tile within the WSI. This is necessary for data visualization, and for creating structured 3D tensors.

To achieve this we have to trick the inference functions by bundling the tiles and tile metadata together into a single variable. tf.keras.Model.predict will discard the 'tile_metadata' variable in a dataset with (tiles, tile_metadata) since it is not needed for inference. To address this we bundle the variables, add a dummy 'y' variable, and pass the tile_metadata through using a simple model wrapper.

_placeholder - show HistomicsStream output_

A simple wrapped model class is initialized with the feature extractor network, and when called, returns the inference result on the tiles `inputs[0]` and the tile metadata `inputs[1]`.

```
# define the wrapped model class
class WrappedModel(tf.keras.Model):
    def __init__(self, extractor, *args, **kwargs):
        super(WrappedModel, self).__init__(*args, **kwargs)
        self.model = model
        
    def call(self, inputs, *args, **kwargs):
        return self.model(inputs[0]), inputs[1]
```
Load the feature extraction model outside of the parallel context, and create the wrapped model inside the parallel context `tf.distribute.MirroredStrategy()`:

```
# create the feature extractor model to be wrapped
model = tf.keras.applications.efficientnet.EfficientNetB3(
        include_top=False, weights='imagenet', input_shape=(t, t, 3),
        pooling='avg')

# create a distributed wrapped model
with tf.distribute.MirroredStrategy().scope():
    
    # wrap the model
    wrapped_model = WrappedModel(model, name='wrapped_model')
```

## Models

We provide basic models to demonstrate how the .tfr can be used for training and validating.

The set-based models in `mil.models.dense` consume flattened tensors (2D), and treat the instances/tiles as an unordered set.

The structured models in `mil.models.convolutional` consume structured tensors (3D), and use convolutional kernels to capture patterns across multiple tiles and scales.

Each model follows a configuration that is friendly for both humans and hyperparameter tuning tools.

_details on model creation interfaces_

## Data format

### Overview

mil stores features in a TFRecord (.tfr) format that can be read from both TensorFlow and PyTorch and other popular data loading packages like DALI. Each .tfr file contains information for one or more slides including:

1. Features
2. User-provided labels and metadata
3. Slide-level metadata
4. Tile-level metadata

Files are produced by `io.writer.write_record` which accepts features and tile metadata from HistomicsStream, as well as a user-provided dictionary of numeric or string variables as scalars, lists, or np.ndarray. See our [basics notebook](https://github.com/PathologyDataScience/mil/blob/main/basics.ipynb) for examples on how to extract features and write .tfr files.

> **Note:** The protocol buffers that TFRecords rely on are limited to 2 GB. This restricts the size of variables that can be stored in a .tfr file. Size can be reduced by adjusting feature extraction parameters including tile overlap, magnification, and use of masks to restrict feature extraction to foreground areas.

### Structured or flattened formats

mil can store features in either _structured_ or _flattened_ format to support different modeling paradigms. The structured format stores features in a three-dimensional format with shape \[height, width, features] that preserved the spatial relationships of tiles within the slide. This allows the application of convolutional, recurrent, or transformer models that can utilize spatial patterns extending across multiple tiles. The flattened format stores features in a two-dimensional format for set-based models that treat tiles as an unordered set. Features can be read in either format regardless of how they are stored, however, we recommend storing features as you plan to utilize them to avoid unecessary overheads.

> **Note:** In flattened format the features are not stored in any particular order. The position of the corresponding tiles/instances that the features originate from is described in the tile metadata (_tile_top_, _tile_left_). For a .tfr containing multiple slides, the features from each slide are not stored in contiguous blocks. The _slide_index_ metadata describes the association between each tile and the slides (see below). This is due to the non-determinism of parallelized data reading and feature extraction pipelines.

### Reading .tfr files

The contents of .tfr files can be inspected using `io.reader.peek` which returns a dictionary of variable names and types stored in the file.

The output of io.reader.peek is required when reading .tfr files are read during model training or inference with TensorFlow. The limitations of TensorFlow prevent obtaining this information when running in graph mode, but io.reader.peek can be run eagerly to acquire this information in advance. For a dataset with uniform .tfr files this information can be obtained from a single file.

In TensorFlow, files can be read by mapping `io.reader.read_record` to a tf.data.TFRecordDataset. read_record returns the features in the requested format, along with the labels, and slide and tile metadata.

> **Note:** The names of user-provided data are prepended with 'label_' to avoid collisions with the standard variables stored in each .tfr. These prefixes are removed by `io.writer.write_record` when reading.

### .tfr variable definitions

A complete description of stored variables is provided below, organized by category.

---

- **File variables**:
    
    `created` (byte) contains the m/d/y h:â€‹m:s when the .tfr file was created.
    
    `histomics_version` (byte) contains the version number of histomics_stream used to extract the features.
    
    `tf_version` (byte) contains the version of TensorFlow used in processing.

---

- **Feature variables**:
    
    `features` (float) is stored in a flattened format. The intended shape is stored in the _shape_ field.
    
    `shape` is a one-dimensional 2- or 3-array describing the shape of the feature array. If a 2-array, _features_ was stored in a flattened format. If a 3-array, _features_ was stored in a structured format. These are interchangable using the `io.transforms` module, and _features_ is transformed to the desired format at load-time. The last dimension is the number of features. 

---

- **Slide variables** - if features from multiple slides are stored in a single .tfr, each slide variable will contain multiple values, one per slide:

    `filename` (byte) contains the filenames of the input slides. Each entry contains the filename for one slide.

    `level` (int) indicates the level from the WSI pyramid used for reading.

    `read_magnification` (float) is the magnification that was read from the WSI file. HistomicsStream will resize what is read if there is a mismatch between the desired magnification and what is available in the WSI.

    `returned_magnification` (float) is the magnification returned by HistomicsStream and used for feature extraction.

    `scan_magnification` (float) is the native magnification used for scanning.

    `slide_name` (byte) contains the names of the slides, possibly without the path or file extentions.

    `slide_group` (byte) contains subject information, indicating what subject the slides belong to. So for example, we could have filename=\[b'\data\TCGA-01-0001-DX1.svs', '\data\TCGA-01-0001-DX2.svs'] and slide_name=\[b'TCGA-01-0001-DX1', b'TCGA-01-0001-DX2'], and slide_group=\[b'TCGA-01-0001].

    `number_pixel_rows_for_chunk` (int) is the height of a chunk (pixels) that is read by HistomicsStream. HistomicsStream reads regions that contain multiple tiles (a chunk) to minimize overhead.

    `number_pixel_columns_for_chunk` (int) is the width of a chunk (pixels).

    `number_pixel_rows_for_tile` (int) is the height of a tile (pixels).

    `number_pixel_columns_for_tile` (int) is the width of a tile (pixels).

    `number_pixel_rows_for_slide` (int) is the height of the slide at `returned_magnification` resolution (pixels).

    `number_pixel_columns_for_slide` (int) is the width of the slide at `returned_magnification` resolution (pixels).

    `number_tile_rows_for_slide` (int) is the height in tiles of the slide at `returned_magnification` resolution. This accounts for tile overlaps. This information is used to create a structured tensor from flattened/unorganized features.

    `number_tile_columns_for_slide` (int) is the width in tiles of the slide at `returned_magnification`. This accounts for tile overlaps.

---

- **Tile variables** - one value per tile:

    `slide_index` (int) when `features` represents multiple slides, `slide_index` indicates which slide each tile came from. So given a tile with features in row `n`, this tile originates from slide `filename[slide_index[n]]`. 

    `chunk_left` (int) is the horizontal position (pixels) of the upper left corner of the chunk that each tile belongs to. This is in pixels at `returned_magnification` resolution. The coordinates follow the array indexing definition, with position (0, 0) in the upper-left corner of the slide, with values increasing left-to-right and top-to-bottom.

    `chunk_top` (int) is the vertical position (pixels) of the upper left corner of the chunk that each tile belongs to.

    `tile_left` (int) is the global horizontal position (pixels) of the upper left corner of each tile. This is in pixels at `returned_magnification` resolution. The coordinates follow the array indexing definition, with position (0, 0) in the upper-left corner of the slide, with values increasing left-to-right and top-to-bottom. This is not the local position with the chunk that the tile resides in.

    `tile_top` (int) is the global horizontal position (pixels) of the upper left corner of each tile.

## Contributing

Black code formatting is required to merge a pull request. Run `black ./mil` from the package root prior to commiting.

Documentation is built using sphinx with the pydata theme. Napoleon and To build the documentation, run 

```
# install documentation dependencies
pip install -U sphinx
pip install pydata_sphinx_theme
pip install myst_parser

# build the .rst files from source
cd ./docs
sphinx-apidoc -f -o ./source ../mil

# build the html
make clean
make html
```

## Future work

Visualization, hyperparameter tuning, additional modeling. Convenience functions for wrapping models and formatting tf.data.Datasets correctly.
